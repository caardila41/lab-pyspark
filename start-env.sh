#!/bin/bash

# Script de inicio rÃ¡pido para Data Engineering with Databricks Cookbook
# Ejecutar en terminal

echo "ğŸš€ Iniciando entorno de Data Engineering..."

# Verificar si Docker estÃ¡ ejecutÃ¡ndose
if ! docker version > /dev/null 2>&1; then
    echo "âŒ Docker no estÃ¡ ejecutÃ¡ndose. Por favor, inicia Docker Desktop"
    exit 1
fi
echo "âœ… Docker estÃ¡ ejecutÃ¡ndose"

# Verificar si estamos en el directorio correcto
if [ ! -f "docker-compose.yml" ]; then
    echo "âŒ No se encontrÃ³ docker-compose.yml. AsegÃºrate de estar en el directorio correcto."
    exit 1
fi

# Construir las imÃ¡genes si no existen
echo "ğŸ”¨ Verificando imÃ¡genes Docker..."
if ! docker images | grep -q "jupyterlab:4.0.2-spark-3.4.1"; then
    echo "ğŸ“¦ Construyendo imÃ¡genes Docker (esto puede tomar varios minutos)..."
    if [ -f "build.sh" ]; then
        chmod +x build.sh
        ./build.sh
    else
        echo "âš ï¸  Script build.sh no encontrado. Construyendo manualmente..."
        docker build -f docker/base/Dockerfile -t base:latest .
        docker build -f docker/spark-base/Dockerfile -t spark-base:3.4.1 .
        docker build -f docker/spark-master/Dockerfile -t spark-master:3.4.1 .
        docker build -f docker/spark-worker/Dockerfile -t spark-worker:3.4.1 .
        docker build -f docker/jupyterlab/Dockerfile -t jupyterlab:4.0.2-spark-3.4.1 .
    fi
else
    echo "âœ… ImÃ¡genes Docker ya existen"
fi

# Detener contenedores existentes si los hay
echo "ğŸ›‘ Deteniendo contenedores existentes..."
docker-compose down

# Iniciar el entorno
echo "ğŸš€ Iniciando servicios..."
docker-compose up -d

# Esperar un momento para que los servicios se inicien
echo "â³ Esperando que los servicios se inicien..."
sleep 30

# Verificar estado de los servicios
echo "ğŸ” Verificando estado de los servicios..."
docker-compose ps

# Mostrar URLs de acceso
echo ""
echo "ğŸ‰ Â¡Entorno iniciado exitosamente!"
echo ""
echo "ğŸ“± URLs de acceso:"
echo "   â€¢ JupyterLab: http://localhost:8888"
echo "   â€¢ Spark Master UI: http://localhost:8080"
echo "   â€¢ Spark Worker 1: http://localhost:8081"
echo "   â€¢ Spark Worker 2: http://localhost:8082"
echo "   â€¢ Spark App UI: http://localhost:4040"
echo ""
echo "ğŸ’¡ Para detener el entorno, ejecuta: docker-compose down"
echo "ğŸ’¡ Para ver logs: docker-compose logs -f"
echo ""
echo "ğŸ“š Â¡Disfruta aprendiendo Data Engineering!" 